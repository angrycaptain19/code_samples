Code From: `autogpt/autogpt/app/main.py` 
Repo Link - https://github.com/Significant-Gravitas/Auto-GPT 



## Code Snippet:

```
def run_auto_gpt(
    continuous: bool,
    continuous_limit: int,
    ai_settings: str,
    prompt_settings: str,
    skip_reprompt: bool,
    speak: bool,
    debug: bool,
    gpt3only: bool,
    gpt4only: bool,
    memory_type: str,
    browser_name: str,
    allow_downloads: bool,
    skip_news: bool,
    working_directory: Path,
    workspace_directory: str | Path,
    install_plugin_deps: bool,
    ai_name: Optional[str] = None,
    ai_role: Optional[str] = None,
    ai_goals: tuple[str] = tuple(),
):
    # Configure logging before we do anything else.
    logger.set_level(logging.DEBUG if debug else logging.INFO)

    config = ConfigBuilder.build_config_from_env(workdir=working_directory)

    # HACK: This is a hack to allow the config into the logger without having to pass it around everywhere
    # or import it directly.
    logger.config = config

    # TODO: fill in llm values here
    check_openai_api_key(config)

    create_config(
        config,
        continuous,
        continuous_limit,
        ai_settings,
        prompt_settings,
        skip_reprompt,
        speak,
        debug,
        gpt3only,
        gpt4only,
        memory_type,
        browser_name,
        allow_downloads,
        skip_news,
    )

    if config.continuous_mode:
        for line in get_legal_warning().split("\n"):
            logger.warn(markdown_to_ansi_style(line), "LEGAL:", Fore.RED)

    if not config.skip_news:
        motd, is_new_motd = get_latest_bulletin()
        if motd:
            motd = markdown_to_ansi_style(motd)
            for motd_line in motd.split("\n"):
                logger.info(motd_line, "NEWS:", Fore.GREEN)
            if is_new_motd and not config.chat_messages_enabled:
                input(
                    Fore.MAGENTA
                    + Style.BRIGHT
                    + "NEWS: Bulletin was updated! Press Enter to continue..."
                    + Style.RESET_ALL
                )

        git_branch = get_current_git_branch()
        if git_branch and git_branch != "stable":
            logger.typewriter_log(
                "WARNING: ",
                Fore.RED,
                f"You are running on `{git_branch}` branch "
                "- this is not a supported branch.",
            )
        if sys.version_info < (3, 10):
            logger.typewriter_log(
                "WARNING: ",
                Fore.RED,
                "You are running on an older version of Python. "
                "Some people have observed problems with certain "
                "parts of Auto-GPT with this version. "
                "Please consider upgrading to Python 3.10 or higher.",
            )

    if install_plugin_deps:
        install_plugin_dependencies()

    # TODO: have this directory live outside the repository (e.g. in a user's
    #   home directory) and have it come in as a command line argument or part of
    #   the env file.
    config.workspace_path = Workspace.init_workspace_directory(
        config, workspace_directory
    )

    # HACK: doing this here to collect some globals that depend on the workspace.
    config.file_logger_path = Workspace.build_file_logger_path(config.workspace_path)

    config.plugins = scan_plugins(config, config.debug_mode)

    # Create a CommandRegistry instance and scan default folder
    command_registry = CommandRegistry.with_command_modules(COMMAND_CATEGORIES, config)

    ai_config = construct_main_ai_config(
        config,
        name=ai_name,
        role=ai_role,
        goals=ai_goals,
    )
    ai_config.command_registry = command_registry
    # print(prompt)

    # add chat plugins capable of report to logger
    if config.chat_messages_enabled:
        for plugin in config.plugins:
            if hasattr(plugin, "can_handle_report") and plugin.can_handle_report():
                logger.info(f"Loaded plugin into logger: {plugin.__class__.__name__}")
                logger.chat_plugins.append(plugin)

    # Initialize memory and make sure it is empty.
    # this is particularly important for indexing and referencing pinecone memory
    memory = get_memory(config)
    memory.clear()
    logger.typewriter_log(
        "Using memory of type:", Fore.GREEN, f"{memory.__class__.__name__}"
    )
    logger.typewriter_log("Using Browser:", Fore.GREEN, config.selenium_web_browser)

    agent = Agent(
        memory=memory,
        command_registry=command_registry,
        triggering_prompt=DEFAULT_TRIGGERING_PROMPT,
        ai_config=ai_config,
        config=config,
    )

    run_interaction_loop(agent)
```

## Coding Assistant Command: 

`Generate Unit Tests`

## Response:

```
import pytest
from unittest.mock import patch
from autogpt.app.main import run_auto_gpt

@pytest.mark.parametrize(
    "continuous, continuous_limit, ai_settings, prompt_settings, skip_reprompt, speak, debug, gpt3only, gpt4only, memory_type, browser_name, allow_downloads, skip_news, working_directory, workspace_directory, install_plugin_deps, ai_name, ai_role, ai_goals",
    [
        # Test case 1: Minimum input values
        (
            False,  # continuous
            0,  # continuous_limit
            "",  # ai_settings
            "",  # prompt_settings
            False,  # skip_reprompt
            False,  # speak
            False,  # debug
            False,  # gpt3only
            False,  # gpt4only
            "",  # memory_type
            "",  # browser_name
            False,  # allow_downloads
            False,  # skip_news
            Path("/path/to/working_directory"),  # working_directory
            "",  # workspace_directory
            False,  # install_plugin_deps
            None,  # ai_name
            None,  # ai_role
            (),  # ai_goals
        ),
        # Test case 2: Maximum input values
        (
            True,  # continuous
            10,  # continuous_limit
            "ai_settings",  # ai_settings
            "prompt_settings",  # prompt_settings
            True,  # skip_reprompt
            True,  # speak
            True,  # debug
            True,  # gpt3only
            True,  # gpt4only
            "memory_type",  # memory_type
            "browser_name",  # browser_name
            True,  # allow_downloads
            True,  # skip_news
            Path("/path/to/working_directory"),  # working_directory
            "/path/to/workspace_directory",  # workspace_directory
            True,  # install_plugin_deps
            "ai_name",  # ai_name
            "ai_role",  # ai_role
            ("goal1", "goal2"),  # ai_goals
        ),
    ]
)
def test_run_auto_gpt(
    continuous, continuous_limit, ai_settings, prompt_settings, skip_reprompt, speak, debug, gpt3only, gpt4only, memory_type, browser_name, allow_downloads, skip_news, working_directory, workspace_directory, install_plugin_deps, ai_name, ai_role, ai_goals
):
    # Arrange

    # Act
    with patch("autogpt.app.main.logger") as mock_logger:
        run_auto_gpt(
            continuous,
            continuous_limit,
            ai_settings,
            prompt_settings,
            skip_reprompt,
            speak,
            debug,
            gpt3only,
            gpt4only,
            memory_type,
            browser_name,
            allow_downloads,
            skip_news,
            working_directory,
            workspace_directory,
            install_plugin_deps,
            ai_name,
            ai_role,
            ai_goals,
        )

    # Assert
    assert mock_logger.set_level.call_count == 1
    assert mock_logger.config == mock_logger.set_level.return_value
    assert mock_logger.set_level.call_args[0][0] == (logging.DEBUG if debug else logging.INFO)
    assert mock_logger.config == mock_logger.set_level.return_value
    assert mock_logger.check_openai_api_key.call_count == 1
    assert mock_logger.create_config.call_count == 1
    assert mock_logger.create_config.call_args[0][0] == mock_logger.config
    assert mock_logger.create_config.call_args[0][1:] == (
        continuous,
        continuous_limit,
        ai_settings,
        prompt_settings,
        skip_reprompt,
        speak,
        debug,
        gpt3only,
        gpt4only,
        memory_type,
        browser_name,
        allow_downloads,
        skip_news,
    )
    assert mock_logger.get_legal_warning.call_count == 1
    assert mock_logger.get_latest_bulletin.call_count == 1
    assert mock_logger.get_current_git_branch.call_count == 1
    assert mock_logger.install_plugin_dependencies.call_count == int(install_plugin_deps)
    assert mock_logger.Workspace.init_workspace_directory.call_count == 1
    assert mock_logger.Workspace.init_workspace_directory.call_args[0][0] == mock_logger.config
    assert mock_logger.Workspace.init_workspace_directory.call_args[0][1] == workspace_directory
    assert mock_logger.Workspace.build_file_logger_path.call_count == 1
    assert mock_logger.Workspace.build_file_logger_path.call_args[0][0] == mock_logger.config.workspace_path
    assert mock_logger.scan_plugins.call_count == 1
    assert mock_logger.scan_plugins.call_args[0][0] == mock_logger.config
    assert mock_logger.CommandRegistry.with_command_modules.call_count == 1
    assert mock_logger.CommandRegistry.with_command_modules.call_args[0][0] == mock_logger.COMMAND_CATEGORIES
    assert mock_logger.construct_main_ai_config.call_count == 1
    assert mock_logger.construct_main_ai_config.call_args[0][0] == mock_logger.config
    assert mock_logger.construct_main_ai_config.call_args[0][1:] == (ai_name, ai_role, ai_goals)
    assert mock_logger.Agent.call_count == 1
    assert mock_logger.Agent.call_args[1]["memory"] == mock_logger.get_memory.return_value
    assert mock_logger.Agent.call_args[1]["command_registry"] == mock_logger.CommandRegistry.with_command_modules.return_value
    assert mock_logger.Agent.call_args[1]["triggering_prompt"] == mock_logger.DEFAULT_TRIGGERING_PROMPT
    assert mock_logger.Agent.call_args[1]["ai_config"] == mock_logger.construct_main_ai_config.return_value
    assert mock_logger.Agent.call_args[1]["config"] == mock_logger.config
    assert mock_logger.run_interaction_loop.call_count == 1
    assert mock_logger.run_interaction_loop.call_args[0][0] == mock_logger.Agent.return_value
```
